{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32428/3150271421.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load('saved_params/torch_vae_beta_binomial_params',\n",
      "/home/pradeep/anaconda3/envs/dip/lib/python3.8/site-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded 0\n",
      "Encoded 10\n",
      "Encoded 20\n",
      "Encoded 30\n",
      "Encoded 40\n",
      "Encoded 50\n",
      "Encoded 60\n",
      "Encoded 70\n",
      "Encoded 80\n",
      "Encoded 90\n",
      "Encoded 100\n",
      "Encoded 110\n",
      "Encoded 120\n",
      "Encoded 130\n",
      "Encoded 140\n",
      "Encoded 150\n",
      "Encoded 160\n",
      "Encoded 170\n",
      "Encoded 180\n",
      "Encoded 190\n",
      "Encoded 200\n",
      "Encoded 210\n",
      "Encoded 220\n",
      "Encoded 230\n",
      "Encoded 240\n",
      "Encoded 250\n",
      "Encoded 260\n",
      "Encoded 270\n",
      "Encoded 280\n",
      "Encoded 290\n",
      "Encoded 300\n",
      "Encoded 310\n",
      "Encoded 320\n",
      "Encoded 330\n",
      "Encoded 340\n",
      "Encoded 350\n",
      "Encoded 360\n",
      "Encoded 370\n",
      "Encoded 380\n",
      "Encoded 390\n",
      "Encoded 400\n",
      "Encoded 410\n",
      "Encoded 420\n",
      "Encoded 430\n",
      "Encoded 440\n",
      "Encoded 450\n",
      "Encoded 460\n",
      "Encoded 470\n",
      "Encoded 480\n",
      "Encoded 490\n",
      "Encoded 500\n",
      "Encoded 510\n",
      "Encoded 520\n",
      "Encoded 530\n",
      "Encoded 540\n",
      "Encoded 550\n",
      "Encoded 560\n",
      "Encoded 570\n",
      "Encoded 580\n",
      "Encoded 590\n",
      "Encoded 600\n",
      "Encoded 610\n",
      "Encoded 620\n",
      "Encoded 630\n",
      "Encoded 640\n",
      "Encoded 650\n",
      "Encoded 660\n",
      "Encoded 670\n",
      "Encoded 680\n",
      "Encoded 690\n",
      "Encoded 700\n",
      "Encoded 710\n",
      "Encoded 720\n",
      "Encoded 730\n",
      "Encoded 740\n",
      "Encoded 750\n",
      "Encoded 760\n",
      "Encoded 770\n",
      "Encoded 780\n",
      "Encoded 790\n",
      "Encoded 800\n",
      "Encoded 810\n",
      "Encoded 820\n",
      "Encoded 830\n",
      "Encoded 840\n",
      "Encoded 850\n",
      "Encoded 860\n",
      "Encoded 870\n",
      "Encoded 880\n",
      "Encoded 890\n",
      "Encoded 900\n",
      "Encoded 910\n",
      "Encoded 920\n",
      "Encoded 930\n",
      "Encoded 940\n",
      "Encoded 950\n",
      "Encoded 960\n",
      "Encoded 970\n",
      "Encoded 980\n",
      "Encoded 990\n",
      "\n",
      "All encoded in 103.22s\n",
      "Compressed message saved to 'compressed_message.bin'.\n",
      "Used 1070592 bits.\n",
      "This is 1.37 bits per pixel\n"
     ]
    }
   ],
   "source": [
    "#Encoding scripts/ compressing scripts\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import util\n",
    "import rans\n",
    "from torch_vae.tvae_beta_binomial import BetaBinomialVAE\n",
    "from torch_vae import tvae_utils\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# from torchvision\n",
    "\n",
    "# our_transforms = transforms.Compose([transforms.PILToTensor(), transforms.Resize((28,28))])\n",
    "# images = []\n",
    "# for img in os.listdir('new_dataset'):\n",
    "#     images.append(our_transforms(Image.open(f'new_dataset/{img}')))\n",
    "\n",
    "# images = torch.stack(images)\n",
    "# print(images.shape)\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "np.seterr(over='raise')\n",
    "\n",
    "prior_precision = 8\n",
    "obs_precision = 14\n",
    "q_precision = 14\n",
    "\n",
    "num_images = 1000\n",
    "\n",
    "compress_lengths = []\n",
    "\n",
    "latent_dim = 50\n",
    "latent_shape = (1, latent_dim)\n",
    "model = BetaBinomialVAE(hidden_dim=200, latent_dim=latent_dim)\n",
    "model.load_state_dict(\n",
    "    torch.load('saved_params/torch_vae_beta_binomial_params',\n",
    "               map_location=lambda storage, location: storage))\n",
    "model.eval()\n",
    "\n",
    "rec_net = tvae_utils.torch_fun_to_numpy_fun(model.encode)\n",
    "gen_net = tvae_utils.torch_fun_to_numpy_fun(model.decode)\n",
    "\n",
    "obs_append = tvae_utils.beta_binomial_obs_append(255, obs_precision)\n",
    "obs_pop = tvae_utils.beta_binomial_obs_pop(255, obs_precision)\n",
    "\n",
    "vae_append = util.vae_append(latent_shape, gen_net, rec_net, obs_append,\n",
    "                             prior_precision, q_precision)\n",
    "vae_pop = util.vae_pop(latent_shape, gen_net, rec_net, obs_pop,\n",
    "                       prior_precision, q_precision)\n",
    "\n",
    "# load some mnist images\n",
    "mnist = datasets.MNIST('data/mnist', train=False, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "images = mnist.test_data[:num_images]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # Resize to 28x28\n",
    "    transforms.ToTensor()         # Convert to tensor\n",
    "])\n",
    "\n",
    "images = [image.float().view(1, -1) for image in images]\n",
    "\n",
    "# randomly generate some 'other' bits\n",
    "other_bits = rng.randint(low=1 << 16, high=1 << 31, size=50, dtype=np.uint32)\n",
    "state = rans.unflatten(other_bits)\n",
    "\n",
    "\n",
    "print_interval = 10\n",
    "encode_start_time = time.time()\n",
    "for i, image in enumerate(images):\n",
    "    state = vae_append(state, image)\n",
    "\n",
    "    if not i % print_interval:\n",
    "        print('Encoded {}'.format(i))\n",
    "\n",
    "    compressed_length = 32 * (len(rans.flatten(state)) - len(other_bits)) / (i+1)\n",
    "    compress_lengths.append(compressed_length)\n",
    "\n",
    "print('\\nAll encoded in {:.2f}s'.format(time.time() - encode_start_time))\n",
    "compressed_message = rans.flatten(state)\n",
    "with open('compressed_image/compressed_message.bin', 'wb') as f:\n",
    "    np.array(compressed_message, dtype=np.uint32).tofile(f)\n",
    "\n",
    "print(\"Compressed message saved to 'compressed_message.bin'.\")\n",
    "compressed_bits = 32 * (len(compressed_message) - len(other_bits))\n",
    "print(\"Used \" + str(compressed_bits) + \" bits.\")\n",
    "print('This is {:.2f} bits per pixel'.format(compressed_bits\n",
    "                                             / (num_images * 784)))\n",
    "\n",
    "np.savetxt('compressed_image/compressed_lengths_cts', np.array(compress_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
